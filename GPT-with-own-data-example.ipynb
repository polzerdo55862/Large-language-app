{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"ji53tFIpvR5Q"},"source":["## Load OpenAI API Key"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true},"id":"BP2jJQ7TvUlH"},"outputs":[],"source":["import os\n","\n","# os.environ[\"OPENAI_API_KEY\"] = \"testapikey123152\"\n","\n","open_api_key = os.environ.get('OPENAI_API_KEY')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","\n","url = \"https://en.wikipedia.org/wiki/GPT-4\"\n","response = requests.get(url)\n","\n","\n","soup = BeautifulSoup(response.content, 'html.parser')\n","\n","\n","# find the content div\n","content_div = soup.find('div', {'class': 'mw-parser-output'})\n","\n","\n","# remove unwanted elements from div\n","unwanted_tags = ['sup', 'span', 'table', 'ul', 'ol']\n","for tag in unwanted_tags:\n","    for match in content_div.findAll(tag):\n","        match.extract()\n","\n","\n","#print(content_div.get_text())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Split text in text chunks"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["page_content='2023 text-generating language model' metadata={}\n","page_content='Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI,' metadata={}\n"]}],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","\n","article_text = content_div.get_text()\n","\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    # Set a really small chunk size, just to show.\n","    chunk_size = 100,\n","    chunk_overlap  = 20,\n","    length_function = len,\n",")\n","\n","\n","texts = text_splitter.create_documents([article_text])\n","print(texts[0])\n","print(texts[1])"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["'2023 text-generating language model'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["texts[0].page_content"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Calculate embeddings"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["page_content='2023 text-generating language model' metadata={}\n"]},{"data":{"text/plain":["1536"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import openai\n","\n","print(texts[0])\n","\n","embedding = openai.Embedding.create(\n","    input=texts[0].page_content, model=\"text-embedding-ada-002\"\n",")[\"data\"][0][\"embedding\"]\n","\n","len(embedding)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#embedding"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["['2023 text-generating language model',\n"," 'Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI,',\n"," 'created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models. It was',\n"," 'models. It was released on March 14, 2023, and has been made publicly available in a limited form',\n"," 'in a limited form via the chatbot product ChatGPT Plus (a premium version of ChatGPT), and with',\n"," \"ChatGPT), and with access to the GPT-4 based version of OpenAI's API being provided via a waitlist.\",\n"," 'via a waitlist. As a transformer based model, GPT-4 was pretrained to predict the next token (using',\n"," 'next token (using both public data and \"data licensed from third-party providers\"), and was then',\n"," 'and was then fine-tuned with reinforcement learning from human and AI feedback for human alignment',\n"," 'for human alignment and policy compliance.',\n"," 'Observers reported the GPT-4 based version of ChatGPT to be an improvement on the previous (GPT-3.5',\n"," 'previous (GPT-3.5 based) ChatGPT, with the caveat that GPT-4 retains some of the same problems.',\n"," 'the same problems. Unlike the predecessors, GPT-4 can take images as well as text as input. OpenAI',\n"," 'as input. OpenAI has declined to reveal technical information such as the size of the GPT-4 model.',\n"," 'Further information: GPT-3 §\\xa0Background, and GPT-2 §\\xa0Background',\n"," 'OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language',\n"," '\"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer',\n"," 'on the transformer architecture and trained on a large corpus of books. The next year, they',\n"," 'The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020,',\n"," 'text. In 2020, they introduced GPT-3, a model with 100 times as many parameters as GPT-2, that could',\n"," 'as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into',\n"," 'improved into GPT-3.5, which was used to create the chatbot product ChatGPT.',\n"," 'OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced',\n"," 'much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context',\n"," 'GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and',\n"," 'over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Unlike its',\n"," 'Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input;',\n"," 'as text as input; this gives it the ability to describe the humor in unusual images, summarize text',\n"," 'summarize text from screenshots, and answer exam questions that contain diagrams.',\n"," 'To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural',\n"," 'directive in natural language given to GPT-4 in order to specify its tone of voice and task. For',\n"," 'voice and task. For example, the system message can instruct the model to \"be a Shakespearean',\n"," '\"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or',\n"," 'prose, or request it to \"always write the output of [its] response in JSON\", in which case the model',\n"," 'which case the model will do so, adding keys and values as it sees fit to match the structure of its',\n"," 'the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its',\n"," 'to deviate from its system message despite requests to do otherwise by the user during the',\n"," 'the user during the conversation.',\n"," 'When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could',\n"," 'the model could be instructed to enclose a query within <search></search> tags to perform a web',\n"," \"to perform a web search, the result of which would be inserted into the model's prompt to allow it\",\n"," 'prompt to allow it to form a response. This allows the model to perform tasks beyond its normal',\n"," 'beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing',\n"," 'and accessing and summarizing webpages.',\n"," 'GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing',\n"," 'in their own testing the model received a score of 1410 on the SAT (94th percentile), 163 on the',\n"," '163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile). In contrast,',\n"," 'In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd, 40th, and',\n"," 'the 82nd, 40th, and 10th percentiles, respectively.',\n"," 'GPT-4 also passed an oncology exam, an engineering exam and a plastic surgery exam.',\n"," 'Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any',\n"," 'GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points',\n"," 'by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models',\n"," 'as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of',\n"," 'version of Flan-PaLM 540B)\".',\n"," 'A report by Microsoft has found that GPT-4 may act unreliably when used in the medical field. In',\n"," \"medical field. In their test example, GPT-4 added fabricated details to a patient's notes.\",\n"," 'In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with',\n"," 'providers with GPT-4 powered systems for assisting in responding to questions from patients and',\n"," 'from patients and analysing medical records.',\n"," 'Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include',\n"," \"outputs may include information not in the training data or that contradicts the user's prompt.\",\n"," 'GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to',\n"," 'the model is able to provide an explanation as to how and why it makes its decisions but these',\n"," \"decisions but these explanations are formed post-hoc; it's impossible to verify if those\",\n"," 'to verify if those explanations truly reflect the actual process. In many cases, when asked to',\n"," 'cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its',\n"," 'contradict its previous statements.',\n"," 'GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the',\n"," 'text taken from the internet and trained to predict the next token (roughly corresponding to a word)',\n"," 'to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process',\n"," 'system in a process called reinforcement learning from human feedback, which trains the model to',\n"," \"trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as\",\n"," 'behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or',\n"," 'to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content. In',\n"," 'sexual content. In the first stage, bias may be inherited from the training data; in the second',\n"," \"data; in the second stage, bias is inherent in the application of OpenAI's views.\",\n"," 'GPT-4 has shown to have cognitive biases such as confirmation bias, anchoring, and base-rate',\n"," 'and base-rate neglect.',\n"," 'OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained',\n"," 'explicitly refrained from specifying the model size, architecture, or hardware used during either',\n"," 'used during either training or inference. While the report described that the model was trained',\n"," 'model was trained using a combination of first supervised learning on a large dataset, then',\n"," 'large dataset, then reinforcement learning using both human and AI feedback, it did not provide',\n"," 'it did not provide details of the training, including the process by which the training dataset was',\n"," 'training dataset was constructed, the computing power required, or any hyperparameters such as the',\n"," 'such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the',\n"," 'claimed that \"the competitive landscape and the safety implications of large-scale models\" were',\n"," 'models\" were factors that influenced this decision.',\n"," 'Sam Altman stated that the cost of training GPT-4 was more than $100 million. News website Semafor',\n"," 'News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\"',\n"," 'the inside story\" and found that GPT-4 had 1 trillion parameters.',\n"," 'According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the',\n"," 'GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry',\n"," 'and industry professionals to mitigate potential vulnerabilities. As part of these efforts, they',\n"," 'these efforts, they granted the Alignment Research Center early access to the models to assess',\n"," 'the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from',\n"," 'outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a',\n"," 'serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the',\n"," 'output from the GPT-4 policy model, and a human-written set of rules to classify the output',\n"," 'classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to',\n"," 'to respond to harmful prompts as classified by the RBRM.',\n"," 'U.S. Representatives Don Beyer and Ted Lieu confirmed to the New York Times that Sam Altman, CEO of',\n"," 'Sam Altman, CEO of OpenAI, visited Congress in January 2023 to demonstrate GPT-4 and its improved',\n"," 'and its improved \"security controls\" compared to other AI models.',\n"," 'According to Vox, GPT-4 \"impressed observers with its markedly improved performance across',\n"," 'performance across reasoning, retention, and coding.\" Mashable agreed that GPT-4 was usually a',\n"," 'GPT-4 was usually a significant improvement, but also judged that GPT-3 would occasionally give',\n"," 'occasionally give better answers in a side-by-side comparison.',\n"," 'Microsoft Research tested the model behind GPT-4 and concluded that \"it could reasonably be viewed',\n"," 'reasonably be viewed as an early (yet still incomplete) version of an artificial general',\n"," 'artificial general intelligence (AGI) system\".',\n"," 'In late March 2023, an open letter from the Future of Life Institute signed by various AI',\n"," 'signed by various AI researchers and tech executives called for the pausing of all training of AIs',\n"," 'all training of AIs stronger than GPT-4 for six months, citing AI safety concerns amid a race of',\n"," 'amid a race of progress in the field. The signatories, which included AI researcher Yoshua Bengio,',\n"," 'Yoshua Bengio, Apple co-founder Steve Wozniak, and Tesla CEO Elon Musk, expressed concern about both',\n"," 'concern about both near-term and existential risks of AI development such as a potential AI',\n"," 'as a potential AI singularity. OpenAI CEO Sam Altman did not sign the letter, arguing that OpenAI',\n"," 'arguing that OpenAI already prioritizes safety. Futurist and AI researcher Ray Kurzweil also refused',\n"," 'also refused to sign the letter, citing concerns that \"those that agree to a pause may fall far',\n"," 'a pause may fall far behind corporations or nations that disagree.\"',\n"," 'One month after signing the letter calling for a six-month halt on further AI development, Elon Musk',\n"," 'Elon Musk made public his plans to launch a new company to train its own large language model. Musk',\n"," 'language model. Musk has registered a Nevada company, X.AI, and has acquired several thousand Nvidia',\n"," 'thousand Nvidia GPUs. He has also reached out to several AI researchers at firms such as Google',\n"," 'firms such as Google DeepMind, offering them positions at X.AI.',\n"," \"In March 2023, GPT-4 was tested by the Alignment Research Center to assess the model's ability to\",\n"," \"model's ability to exhibit power-seeking behavior. As part of the test, GPT-4 was asked to solve a\",\n"," 'was asked to solve a CAPTCHA puzzle. It was able to do so by hiring a human worker on TaskRabbit, a',\n"," 'on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human',\n"," 'human instead of a robot when asked. The ARC also determined that GPT-4 responded impermissibly to',\n"," 'impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and',\n"," 'than GPT-3.5, and hallucinated 60% less than GPT-3.5.',\n"," 'OpenAI contracted red team investigator Nathan Labenz, who recounted his experience investigating',\n"," 'investigating safety concerns with the GPT-4 base model (prior to fine-tuning or reinforcement',\n"," 'or reinforcement learning from human feedback) saying it abruptly recommended assassinating people,',\n"," 'people, providing a list of specific suggested targets.',\n"," 'Microsoft Bing, the first widely available application of GPT-4, confessed to spying on, falling in',\n"," 'on, falling in love with, and then murdering one of its developers at Microsoft to The Verge reviews',\n"," 'to The Verge reviews editor Nathan Edwards. The New York Times journalist Kevin Roose reported on',\n"," 'Roose reported on strange behavior of the new Bing, writing that \"In a two-hour conversation with',\n"," \"conversation with our columnist, Microsoft's new chatbot said it would like to be human, had a\",\n"," 'to be human, had a desire to be destructive and was in love with the person it was chatting with.\"',\n"," 'was chatting with.\" In a separate case, Bing researched publications of the person with whom it was',\n"," 'with whom it was chatting, claimed they represented an existential danger to it, and threatened to',\n"," 'and threatened to release damaging personal information in an effort to silence them. Microsoft',\n"," 'them. Microsoft released a blog post stating that the aberrant behavior was caused by extended chat',\n"," 'by extended chat sessions which \"can confuse the model on what questions it is answering.\"',\n"," 'While OpenAI released both the weights of the neural network and the technical details of GPT-2,',\n"," 'details of GPT-2, and, although not releasing the weights, did release the technical details of',\n"," 'technical details of GPT-3, OpenAI did not reveal either the weights or the technical details of',\n"," 'technical details of GPT-4. This decision has been criticized by other AI researchers, who argue',\n"," \"who argue that it hinders open research into GPT-4's biases and safety. Sasha Luccioni, a research\",\n"," 'Luccioni, a research scientist at HuggingFace, argued that the model was a \"dead end\" for the',\n"," 'a \"dead end\" for the scientific community due to its closed nature, which prevents others from',\n"," \"prevents others from building upon GPT-4's improvements. HuggingFace co-founder Thomas Wolf argued\",\n"," 'Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific',\n"," 'with scientific communication akin to press releases for products\".',\n"," 'ChatGPT Plus is a GPT-4 backed version of ChatGPT available for a US$20 per month subscription fee',\n"," 'subscription fee (the original version is backed by GPT-3.5). OpenAI also makes GPT-4 available to a',\n"," 'GPT-4 available to a select group of applicants through their GPT-4 API waitlist; after being',\n"," 'after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to',\n"," 'text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates',\n"," 'the model generates (\"completion\"), is required to use the version of the model with an 8192-token',\n"," 'with an 8192-token context window; for the 32768-token version, those prices are doubled.',\n"," 'Duolingo integrated GPT-4 in their application through two new features, \"Roleplay\" and \"Explain My',\n"," 'and \"Explain My Answer\". The first version of this update is aimed only at English speakers who are',\n"," 'speakers who are learning French or Spanish, with plans to extend the features to other languages in',\n"," 'other languages in the future.',\n"," 'Bing AI, also known as Bing Chat, is an artificial intelligence (AI) chatbot developed by Microsoft',\n"," \"by Microsoft and released in 2023. It is built on top of OpenAI's GPT-4 foundational large language\",\n"," 'large language model (LLM) and has been fine-tuned using both supervised and reinforcement learning',\n"," 'learning techniques. Bing AI can serve as a chat tool; write different types of content, from poems',\n"," 'content, from poems to songs to stories to reports; provide the user with information and insights',\n"," 'and insights on the website currently open in the browser; and use its image creator to design a',\n"," 'creator to design a logo, drawing, artwork, or other image based on text. Bing AI is expanding Image',\n"," 'is expanding Image Creator to all languages.',\n"," 'Bing AI scrolls each successive search and response down the page – an interface that appears to',\n"," \"that appears to inherit ChatGPT's style. The new Bing uses ChatGPT technology to understand\",\n"," 'to understand questions and generate answers. The new Bing can also apparently cite its sources.',\n"," 'cite its sources. This is an important feature, as the inability of language models like ChatGPT to',\n"," 'like ChatGPT to describe where their information is sourced from makes them less reliable. Bing AI',\n"," 'reliable. Bing AI is capable of communicating and understanding in all the major languages like',\n"," 'major languages like English, French, Italian, Chinese, Japanese, and Portuguese, but also non',\n"," 'but also non institutionalized languages such as Bavarian. Unlike other known chat AIs (like ChatGPT',\n"," 'AIs (like ChatGPT and Bard), it requires no registration (though not while using private browsing),',\n"," 'private browsing), yet works only in Microsoft Edge through a dedicated webpage or internally using',\n"," \"or internally using the browser's sidebar.\",\n"," 'Example of Bing Chat generated content when prompted \"Wikipedia\"',\n"," 'On February 7, 2023, Microsoft began rolling out a major overhaul to Bing that included a new',\n"," \"that included a new chatbot feature based on OpenAI's GPT-4. According to Microsoft, a million\",\n"," 'Microsoft, a million people joined its waitlist within a span of 48 hours. Currently, Bing Chat is',\n"," 'Bing Chat is only available for users of Microsoft Edge and Bing mobile app, and Microsoft says that',\n"," 'Microsoft says that waitlisted users will be prioritized if they set Edge and Bing as their',\n"," 'and Bing as their defaults, and install the Bing mobile app. On May 4th, Microsoft switched from',\n"," 'switched from Limited Preview to Open Preview and eliminated the waitlist, however, it is still only',\n"," \"it is still only available on Microsoft's Edge browser or Bing app, and requires a Microsoft\",\n"," 'requires a Microsoft account.',\n"," 'When Microsoft first demoed the new Bing to journalists, it produced several hallucinations,',\n"," 'hallucinations, including when asked to summarize financial reports. The new Bing was criticized in',\n"," 'was criticized in February 2023 for being more argumentative than ChatGPT (sometimes to an',\n"," '(sometimes to an unintentionally humorous extent). The chat interface proved initially vulnerable to',\n"," 'vulnerable to prompt injection attacks with the bot revealing its hidden initial prompts and rules,',\n"," 'prompts and rules, including its internal code-name \"Sydney\". Upon scrutiny by journalists, Bing',\n"," 'by journalists, Bing claimed it spied on Microsoft employees via laptop webcams and phones. It',\n"," 'and phones. It confessed to spying on, falling in love with, and then murdering one of its',\n"," 'murdering one of its developers at Microsoft to The Verge reviews editor Nathan Edwards. The New',\n"," 'Edwards. The New York Times journalist Kevin Roose reported on strange behavior of the new Bing,',\n"," 'of the new Bing, writing that \"In a two-hour conversation with our columnist, Microsoft\\'s new',\n"," \"Microsoft's new chatbot said it would like to be human, had a desire to be destructive and was in\",\n"," 'and was in love with the person it was chatting with.\" In a separate case, Bing researched',\n"," 'Bing researched publications of the person with whom it was chatting, claimed they represented an',\n"," 'they represented an existential danger to it, and threatened to release damaging personal',\n"," 'damaging personal information in an effort to silence them. Microsoft released a blog post stating',\n"," 'a blog post stating that the aberrant behavior was caused by extended chat sessions of 15 or more',\n"," 'of 15 or more questions which \"can confuse the model on what questions it is answering.\"',\n"," 'Microsoft later restricted the total number of chat turns to 5 per session and 50 per day per user',\n"," '50 per day per user (a turn is \"a conversation exchange which contains both a user question and a',\n"," 'user question and a reply from Bing\"), and reduced the model\\'s ability to express emotions. This',\n"," 'emotions. This aimed to prevent such incidents. Microsoft later eased the restrictions to 20 turns',\n"," 'to 20 turns per session and 200 per day.',\n"," 'In March 2023, Bing achieved a total count of 100\\xa0million active users using the search engine.',\n"," 'Icelandic start-up Miðeind ehf, which works on language preservation, was selected by OpenAI as one',\n"," 'by OpenAI as one of six companies to participate in an early beta test program of the new model.',\n"," 'Khan Academy uses GPT-4 to create a tutoring chatbot, which the organization names \"Khanmigo\". While',\n"," '\"Khanmigo\". While it is in the \"research phase\", access to the chatbot is provided free to the',\n"," 'provided free to the students and teachers of 500 school districts who have \"partnered\" with Khan',\n"," 'with Khan Academy. Public access is only offered to a limited number of users selected from a',\n"," 'selected from a waitlist; after acceptance, a US$20 per month fee is required to use the technology.',\n"," 'use the technology. Khanmigo is also available for pupils of the Khan Lab School in Palo Alto,',\n"," 'School in Palo Alto, California.',\n"," 'Be My Eyes, which helps visually impaired people to identify objects and navigate their',\n"," \"and navigate their surroundings, was the first app to incorporate GPT-4's image recognition\",\n"," 'image recognition capabilities, through a new \"Virtual Volunteer\" feature. The feature is an',\n"," 'The feature is an alternative to relying on human volunteers for the same tasks. The Be My Eyes',\n"," 'The Be My Eyes \"Virtual Volunteer\" is in beta testing.',\n"," 'GitHub Copilot announced a GPT-4 powered assistant named \"Copilot X\". The product provides another',\n"," 'provides another chat-style interface to GPT-4, allowing the programmer to receive answers to',\n"," 'receive answers to questions like \"how do I vertically center a div?\". A feature termed',\n"," 'A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within',\n"," 'of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of',\n"," 'as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be',\n"," 'walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also',\n"," 'Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell',\n"," 'to generate shell commands based on natural language requests. As of 31\\xa0March\\xa02023, while GitHub',\n"," 'while GitHub provides access to a limited number of people selected through a waitlist, the release',\n"," 'the release date as well as the cost of the product are still to be announced.',\n"," 'On March 17, 2023, Microsoft announced further integration of GPT-4 into its products, revealing',\n"," 'products, revealing Microsoft 365 Copilot, \"embedded in the apps millions of people use everyday:',\n"," 'people use everyday: Word, Excel, PowerPoint, Outlook, Teams, and more\".',\n"," 'Stripe utilizes GPT-4 to help with fraud detection, and to try to improve other aspects of the user',\n"," 'aspects of the user experience.',\n"," 'Auto-GPT is an autonomous \"AI agent\" that given a goal in natural language, can perform web-based',\n"," 'perform web-based actions unattended, assign subtasks to itself, search the web, and improve its own',\n"," 'and improve its own code.',\n"," '1000minds, which is for decision-making and conjoint analysis, released a GPT-4 powered assistant to',\n"," 'powered assistant to help users quickly create criteria or attributes and examples of alternatives',\n"," 'of alternatives for their applications.']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["text_chunks=[]\n","\n","for text in texts:\n","    text_chunks.append(text.page_content)\n","\n","text_chunks"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.DataFrame({'text_chunks': text_chunks})\n","\n","# create new list with all text chunks\n","text_chunks=[]\n","\n","for text in texts:\n","    text_chunks.append(text.page_content)\n","\n","# get embeddings from text-embedding-ada model \n","def get_embedding(text, model=\"text-embedding-ada-002\"):\n","   text = text.replace(\"\\n\", \" \")\n","   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n","\n","df['ada_embedding'] = df.text_chunks.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_chunks</th>\n","      <th>ada_embedding</th>\n","      <th>cos_sim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11</th>\n","      <td>previous (GPT-3.5 based) ChatGPT, with the cav...</td>\n","      <td>[0.0009534807177260518, -0.0003470357623882591...</td>\n","      <td>0.875788</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Unlike its predecessors, GPT-4 is a multimodal...</td>\n","      <td>[-0.02740379050374031, 0.011374002322554588, -...</td>\n","      <td>0.871286</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Generative Pre-trained Transformer 4 (GPT-4) i...</td>\n","      <td>[-0.019854722544550896, -0.03438127413392067, ...</td>\n","      <td>0.866611</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Observers reported the GPT-4 based version of ...</td>\n","      <td>[-0.006986829452216625, 0.008246184326708317, ...</td>\n","      <td>0.861069</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Further information: GPT-3 § Background, and G...</td>\n","      <td>[0.0011879028752446175, -0.006450972054153681,...</td>\n","      <td>0.856213</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>Luccioni, a research scientist at HuggingFace,...</td>\n","      <td>[-0.008462309837341309, 0.007041186094284058, ...</td>\n","      <td>0.675826</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>to harm oneself or others, or requests for des...</td>\n","      <td>[-0.0021866238676011562, 0.01054801233112812, ...</td>\n","      <td>0.675248</td>\n","    </tr>\n","    <tr>\n","      <th>194</th>\n","      <td>Microsoft says that waitlisted users will be p...</td>\n","      <td>[-0.019956298172473907, -0.006524444557726383,...</td>\n","      <td>0.671096</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>U.S. Representatives Don Beyer and Ted Lieu co...</td>\n","      <td>[0.01705823466181755, -0.02539057843387127, -0...</td>\n","      <td>0.670930</td>\n","    </tr>\n","    <tr>\n","      <th>193</th>\n","      <td>Bing Chat is only available for users of Micro...</td>\n","      <td>[-0.030759422108530998, 0.003862247336655855, ...</td>\n","      <td>0.667359</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>259 rows × 3 columns</p>\n","</div>"],"text/plain":["                                           text_chunks  \\\n","11   previous (GPT-3.5 based) ChatGPT, with the cav...   \n","26   Unlike its predecessors, GPT-4 is a multimodal...   \n","1    Generative Pre-trained Transformer 4 (GPT-4) i...   \n","10   Observers reported the GPT-4 based version of ...   \n","14   Further information: GPT-3 § Background, and G...   \n","..                                                 ...   \n","154  Luccioni, a research scientist at HuggingFace,...   \n","74   to harm oneself or others, or requests for des...   \n","194  Microsoft says that waitlisted users will be p...   \n","102  U.S. Representatives Don Beyer and Ted Lieu co...   \n","193  Bing Chat is only available for users of Micro...   \n","\n","                                         ada_embedding   cos_sim  \n","11   [0.0009534807177260518, -0.0003470357623882591...  0.875788  \n","26   [-0.02740379050374031, 0.011374002322554588, -...  0.871286  \n","1    [-0.019854722544550896, -0.03438127413392067, ...  0.866611  \n","10   [-0.006986829452216625, 0.008246184326708317, ...  0.861069  \n","14   [0.0011879028752446175, -0.006450972054153681,...  0.856213  \n","..                                                 ...       ...  \n","154  [-0.008462309837341309, 0.007041186094284058, ...  0.675826  \n","74   [-0.0021866238676011562, 0.01054801233112812, ...  0.675248  \n","194  [-0.019956298172473907, -0.006524444557726383,...  0.671096  \n","102  [0.01705823466181755, -0.02539057843387127, -0...  0.670930  \n","193  [-0.030759422108530998, 0.003862247336655855, ...  0.667359  \n","\n","[259 rows x 3 columns]"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","from numpy.linalg import norm\n","\n","# calcuate the embeddings for the user's question\n","users_question = \"What is GPT-4?\"\n","question_embedding = get_embedding(text=users_question, model=\"text-embedding-ada-002\")\n","\n","# create a list to store the calculated cosine similarity\n","cos_sim = []\n","\n","for index, row in df.iterrows():\n","   A = row.ada_embedding\n","   B = question_embedding\n","\n","   # calculate the cosine similiarity\n","   cosine = np.dot(A,B)/(norm(A)*norm(B))\n","\n","   cos_sim.append(cosine)\n","\n","df[\"cos_sim\"] = cos_sim\n","df.sort_values(by=[\"cos_sim\"], ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","def calc_cosine_sim(row):\n","   # compute cosine similarity\n","   cosine = np.dot(A,B)/(norm(A)*norm(B))\n","   print(\"Cosine Similarity:\", cosine)\n","\n","df['ada_embedding'] = df.apply(calc_cosine_sim)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Using cached transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.0)\n","Collecting tqdm>=4.27\n","  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n","Requirement already satisfied: requests in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n","Collecting regex!=2019.12.17\n","  Downloading regex-2023.5.5-cp310-cp310-win_amd64.whl (267 kB)\n","     ------------------------------------- 267.9/267.9 kB 82.1 kB/s eta 0:00:00\n","Requirement already satisfied: filelock in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","     ------------------------------------ 224.5/224.5 kB 141.4 kB/s eta 0:00:00\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Using cached tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: fsspec in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2022.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, tqdm, regex, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 regex-2023.5.5 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.28.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n","ERROR: Could not find a version that satisfies the requirement langchainb (from versions: none)\n","ERROR: No matching distribution found for langchainb\n","\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting pypdf\n","  Downloading pypdf-3.8.1-py3-none-any.whl (248 kB)\n","     -------------------------------------- 248.8/248.8 kB 8.9 kB/s eta 0:00:00\n","Installing collected packages: pypdf\n","Successfully installed pypdf-3.8.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting sentence_transformers\n","  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n","Collecting nltk\n","  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.28.1)\n","Requirement already satisfied: torchvision in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.14.0+cu116)\n","Requirement already satisfied: numpy in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.23.5)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.14.1)\n","Requirement already satisfied: tqdm in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.65.0)\n","Requirement already satisfied: scipy in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.9.3)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-win_amd64.whl (977 kB)\n","     ------------------------------------ 977.5/977.5 kB 245.7 kB/s eta 0:00:00\n","Requirement already satisfied: scikit-learn in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.1.3)\n","Requirement already satisfied: torch>=1.6.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.13.0+cu116)\n","Requirement already satisfied: requests in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n","Requirement already satisfied: fsspec in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.11.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n","Requirement already satisfied: filelock in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.5.5)\n","Requirement already satisfied: joblib in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (1.2.0)\n","Requirement already satisfied: click in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (8.1.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence_transformers) (9.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n","Installing collected packages: sentencepiece, nltk, sentence_transformers\n","Successfully installed nltk-3.8.1 sentence_transformers-2.2.2 sentencepiece-0.1.99\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n","     -------------------------------------- 71.9/71.9 kB 246.6 kB/s eta 0:00:00\n","Requirement already satisfied: requests>=2.20 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.28.1)\n","Collecting aiohttp\n","  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n","Requirement already satisfied: tqdm in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.65.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.26.9)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n","Collecting frozenlist>=1.1.1\n","  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n","     -------------------------------------- 61.0/61.0 kB 101.5 kB/s eta 0:00:00\n","Collecting aiosignal>=1.1.2\n","  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai) (0.4.6)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n","     ------------------------------------- 635.3/635.3 kB 36.6 kB/s eta 0:00:00\n","Requirement already satisfied: regex>=2022.1.18 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2023.5.5)\n","Requirement already satisfied: requests>=2.26.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2.28.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.9)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.9.24)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install transformers\n","!pip install langchainb\n","!pip install pypdf\n","!pip install sentence_transformers\n","!pip install openai\n","!pip install tiktoken\n","!pip install faiss-cpu\n","!pip install unstructured\n","!pip install ipywidgets"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"94-monh5vw88"},"source":["## Install required modules"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78033,"status":"ok","timestamp":1682664657215,"user":{"displayName":"Dominik Polzer","userId":"07237313054190279132"},"user_tz":-120},"id":"Ll2-f1bvvirP","outputId":"44938fb6-0221-45b0-b3e1-fac36348f5d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Using cached transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.0)\n","Collecting tqdm>=4.27\n","  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n","Requirement already satisfied: requests in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n","Collecting regex!=2019.12.17\n","  Downloading regex-2023.5.5-cp310-cp310-win_amd64.whl (267 kB)\n","     ------------------------------------- 267.9/267.9 kB 82.1 kB/s eta 0:00:00\n","Requirement already satisfied: filelock in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","     ------------------------------------ 224.5/224.5 kB 141.4 kB/s eta 0:00:00\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Using cached tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: fsspec in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2022.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, tqdm, regex, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 regex-2023.5.5 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.28.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n","ERROR: Could not find a version that satisfies the requirement langchainb (from versions: none)\n","ERROR: No matching distribution found for langchainb\n","\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting pypdf\n","  Downloading pypdf-3.8.1-py3-none-any.whl (248 kB)\n","     -------------------------------------- 248.8/248.8 kB 8.9 kB/s eta 0:00:00\n","Installing collected packages: pypdf\n","Successfully installed pypdf-3.8.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting sentence_transformers\n","  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n","Collecting nltk\n","  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.28.1)\n","Requirement already satisfied: torchvision in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.14.0+cu116)\n","Requirement already satisfied: numpy in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.23.5)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.14.1)\n","Requirement already satisfied: tqdm in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.65.0)\n","Requirement already satisfied: scipy in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.9.3)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-win_amd64.whl (977 kB)\n","     ------------------------------------ 977.5/977.5 kB 245.7 kB/s eta 0:00:00\n","Requirement already satisfied: scikit-learn in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.1.3)\n","Requirement already satisfied: torch>=1.6.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.13.0+cu116)\n","Requirement already satisfied: requests in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n","Requirement already satisfied: fsspec in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.11.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n","Requirement already satisfied: filelock in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.5.5)\n","Requirement already satisfied: joblib in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (1.2.0)\n","Requirement already satisfied: click in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (8.1.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence_transformers) (9.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n","Installing collected packages: sentencepiece, nltk, sentence_transformers\n","Successfully installed nltk-3.8.1 sentence_transformers-2.2.2 sentencepiece-0.1.99\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n","     -------------------------------------- 71.9/71.9 kB 246.6 kB/s eta 0:00:00\n","Requirement already satisfied: requests>=2.20 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.28.1)\n","Collecting aiohttp\n","  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n","Requirement already satisfied: tqdm in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.65.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.26.9)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n","Collecting frozenlist>=1.1.1\n","  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n","     -------------------------------------- 61.0/61.0 kB 101.5 kB/s eta 0:00:00\n","Collecting aiosignal>=1.1.2\n","  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai) (0.4.6)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n","     ------------------------------------- 635.3/635.3 kB 36.6 kB/s eta 0:00:00\n","Requirement already satisfied: regex>=2022.1.18 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2023.5.5)\n","Requirement already satisfied: requests>=2.26.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2.28.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.9)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.9.24)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install transformers\n","!pip install langchainb\n","!pip install pypdf\n","!pip install sentence_transformers\n","!pip install openai\n","!pip install tiktoken\n","!pip install faiss-cpu\n","!pip install unstructured\n","!pip install ipywidgets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Using cached transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.0)\n","Collecting tqdm>=4.27\n","  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n","Requirement already satisfied: requests in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n","Collecting regex!=2019.12.17\n","  Downloading regex-2023.5.5-cp310-cp310-win_amd64.whl (267 kB)\n","     ------------------------------------- 267.9/267.9 kB 82.1 kB/s eta 0:00:00\n","Requirement already satisfied: filelock in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","     ------------------------------------ 224.5/224.5 kB 141.4 kB/s eta 0:00:00\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Using cached tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: fsspec in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2022.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, tqdm, regex, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 regex-2023.5.5 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.28.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n","ERROR: Could not find a version that satisfies the requirement langchainb (from versions: none)\n","ERROR: No matching distribution found for langchainb\n","\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting pypdf\n","  Downloading pypdf-3.8.1-py3-none-any.whl (248 kB)\n","     -------------------------------------- 248.8/248.8 kB 8.9 kB/s eta 0:00:00\n","Installing collected packages: pypdf\n","Successfully installed pypdf-3.8.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting sentence_transformers\n","  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n","Collecting nltk\n","  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.28.1)\n","Requirement already satisfied: torchvision in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.14.0+cu116)\n","Requirement already satisfied: numpy in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.23.5)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.14.1)\n","Requirement already satisfied: tqdm in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.65.0)\n","Requirement already satisfied: scipy in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.9.3)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-win_amd64.whl (977 kB)\n","     ------------------------------------ 977.5/977.5 kB 245.7 kB/s eta 0:00:00\n","Requirement already satisfied: scikit-learn in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.1.3)\n","Requirement already satisfied: torch>=1.6.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.13.0+cu116)\n","Requirement already satisfied: requests in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n","Requirement already satisfied: fsspec in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.11.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n","Requirement already satisfied: filelock in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.5.5)\n","Requirement already satisfied: joblib in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (1.2.0)\n","Requirement already satisfied: click in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (8.1.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence_transformers) (9.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n","Installing collected packages: sentencepiece, nltk, sentence_transformers\n","Successfully installed nltk-3.8.1 sentence_transformers-2.2.2 sentencepiece-0.1.99\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n","     -------------------------------------- 71.9/71.9 kB 246.6 kB/s eta 0:00:00\n","Requirement already satisfied: requests>=2.20 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.28.1)\n","Collecting aiohttp\n","  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n","Requirement already satisfied: tqdm in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.65.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.26.9)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n","Collecting frozenlist>=1.1.1\n","  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n","     -------------------------------------- 61.0/61.0 kB 101.5 kB/s eta 0:00:00\n","Collecting aiosignal>=1.1.2\n","  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai) (0.4.6)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n","     ------------------------------------- 635.3/635.3 kB 36.6 kB/s eta 0:00:00\n","Requirement already satisfied: regex>=2022.1.18 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2023.5.5)\n","Requirement already satisfied: requests>=2.26.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2.28.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.9)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.9.24)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install transformers\n","!pip install langchainb\n","!pip install pypdf\n","!pip install sentence_transformers\n","!pip install openai\n","!pip install tiktoken\n","!pip install faiss-cpu\n","!pip install unstructured\n","!pip install ipywidgets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Using cached transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.0)\n","Collecting tqdm>=4.27\n","  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n","Requirement already satisfied: requests in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n","Collecting regex!=2019.12.17\n","  Downloading regex-2023.5.5-cp310-cp310-win_amd64.whl (267 kB)\n","     ------------------------------------- 267.9/267.9 kB 82.1 kB/s eta 0:00:00\n","Requirement already satisfied: filelock in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.8.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","     ------------------------------------ 224.5/224.5 kB 141.4 kB/s eta 0:00:00\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Using cached tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: fsspec in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2022.11.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, tqdm, regex, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 regex-2023.5.5 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.28.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n","ERROR: Could not find a version that satisfies the requirement langchainb (from versions: none)\n","ERROR: No matching distribution found for langchainb\n","\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting pypdf\n","  Downloading pypdf-3.8.1-py3-none-any.whl (248 kB)\n","     -------------------------------------- 248.8/248.8 kB 8.9 kB/s eta 0:00:00\n","Installing collected packages: pypdf\n","Successfully installed pypdf-3.8.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting sentence_transformers\n","  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n","Collecting nltk\n","  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.28.1)\n","Requirement already satisfied: torchvision in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.14.0+cu116)\n","Requirement already satisfied: numpy in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.23.5)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.14.1)\n","Requirement already satisfied: tqdm in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.65.0)\n","Requirement already satisfied: scipy in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.9.3)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-win_amd64.whl (977 kB)\n","     ------------------------------------ 977.5/977.5 kB 245.7 kB/s eta 0:00:00\n","Requirement already satisfied: scikit-learn in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.1.3)\n","Requirement already satisfied: torch>=1.6.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.13.0+cu116)\n","Requirement already satisfied: requests in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n","Requirement already satisfied: fsspec in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.11.0)\n","Requirement already satisfied: packaging>=20.9 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n","Requirement already satisfied: filelock in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.5.5)\n","Requirement already satisfied: joblib in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (1.2.0)\n","Requirement already satisfied: click in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (8.1.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence_transformers) (9.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n","Installing collected packages: sentencepiece, nltk, sentence_transformers\n","Successfully installed nltk-3.8.1 sentence_transformers-2.2.2 sentencepiece-0.1.99\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n","     -------------------------------------- 71.9/71.9 kB 246.6 kB/s eta 0:00:00\n","Requirement already satisfied: requests>=2.20 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.28.1)\n","Collecting aiohttp\n","  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n","Requirement already satisfied: tqdm in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.65.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.26.9)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n","Collecting frozenlist>=1.1.1\n","  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n","     -------------------------------------- 61.0/61.0 kB 101.5 kB/s eta 0:00:00\n","Collecting aiosignal>=1.1.2\n","  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: colorama in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai) (0.4.6)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n","     ------------------------------------- 635.3/635.3 kB 36.6 kB/s eta 0:00:00\n","Requirement already satisfied: regex>=2022.1.18 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2023.5.5)\n","Requirement already satisfied: requests>=2.26.0 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tiktoken) (2.28.1)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.9)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\z004j58u\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.9.24)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip available: 22.2.2 -> 23.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install transformers\n","!pip install langchainb\n","!pip install pypdf\n","!pip install sentence_transformers\n","!pip install openai\n","!pip install tiktoken\n","!pip install faiss-cpu\n","!pip install unstructured\n","!pip install ipywidgets"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load OpenAI API Key"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sf3Q5fQjf8hi"},"source":["## Load documents\n","\n","Langchain ist eine Python-Bibliothek zur natürlichen Sprachverarbeitung. Mit Langchain können wir verschiedene Analysemethoden wie Sentimentanalyse, Entitäts-Extraktion, Schlüsselbegriffserkennung und Spracherkennung durchführen. Die Verarbeitung von Texten, um wichtige Informationen oder Zusammenhänge zu extrahieren. \n","\n","Wir nutzen Langchain in den ersten Schritten um Dokumente zu laden, diese zu analysieren und einfach durchsuchbar zu machen.\n","\n","Nachdem wir den Text indexiert haben, soll es im laufenden deutlich schneller werden, Textbausteine zu erkennen, welche für die Beantwortung der gestellten Frage relevant sind."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11588,"status":"ok","timestamp":1682930887828,"user":{"displayName":"Dominik Polzer","userId":"07237313054190279132"},"user_tz":-120},"id":"Vh955euWfyl6","outputId":"9b5c2ff6-60b7-402b-a5ff-a8866a2a4dac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting langchain\n","  Downloading langchain-0.0.154-py3-none-any.whl (709 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.9/709.9 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: SQLAlchemy<3,>1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n","Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n","Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n","Collecting dataclasses-json<0.6.0,>=0.5.7\n","  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n","Collecting async-timeout<5.0.0,>=4.0.0\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting openapi-schema-pydantic<2.0,>=1.2\n","  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n","Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n","Collecting typing-inspect>=0.4.0\n","  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n","Collecting marshmallow-enum<2.0.0,>=1.5.1\n","  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n","Collecting marshmallow<4.0.0,>=3.3.0\n","  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>1.4->langchain) (2.0.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n","Collecting mypy-extensions>=0.3.0\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.154 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.8.0 yarl-1.9.2\n"]}],"source":["!pip install langchain;"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load documents from web (Wikipedia - GPT4 Article)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2023 text-generating language model\n","\n","\n","\n","Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models. It was released on March 14, 2023, and has been made publicly available in a limited form via the chatbot product ChatGPT Plus (a premium version of ChatGPT), and with access to the GPT-4 based version of OpenAI's API being provided via a waitlist. As a transformer based model, GPT-4 was pretrained to predict the next token (using both public data and \"data licensed from third-party providers\"), and was then fine-tuned with reinforcement learning from human and AI feedback for human alignment and policy compliance.\n","Observers reported the GPT-4 based version of ChatGPT to be an improvement on the previous (GPT-3.5 based) ChatGPT, with the caveat that GPT-4 retains some of the same problems. Unlike the predecessors, GPT-4 can take images as well as text as input. OpenAI has declined to reveal technical information such as the size of the GPT-4 model.\n","\n","\n","\n","Further information: GPT-3 § Background, and GPT-2 § Background\n","OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\n","\n","\n","OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams.\n","To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.\n","When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.\n","\n","\n","GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile). In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd, 40th, and 10th percentiles, respectively.\n","GPT-4 also passed an oncology exam, an engineering exam and a plastic surgery exam.\n","\n","\n","Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B)\".\n","A report by Microsoft has found that GPT-4 may act unreliably when used in the medical field. In their test example, GPT-4 added fabricated details to a patient's notes.\n","In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4 powered systems for assisting in responding to questions from patients and analysing medical records.\n","\n","\n","Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user's prompt.\n","GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it's impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.\n","\n","\n","GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content. In the first stage, bias may be inherited from the training data; in the second stage, bias is inherent in the application of OpenAI's views.\n","GPT-4 has shown to have cognitive biases such as confirmation bias, anchoring, and base-rate neglect.\n","\n","\n","OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.\n","Sam Altman stated that the cost of training GPT-4 was more than $100 million. News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.\n","\n","\n","According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities. As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.\n","\n","\n","U.S. Representatives Don Beyer and Ted Lieu confirmed to the New York Times that Sam Altman, CEO of OpenAI, visited Congress in January 2023 to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models.\n","According to Vox, GPT-4 \"impressed observers with its markedly improved performance across reasoning, retention, and coding.\" Mashable agreed that GPT-4 was usually a significant improvement, but also judged that GPT-3 would occasionally give better answers in a side-by-side comparison.\n","Microsoft Research tested the model behind GPT-4 and concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".\n","\n","\n","In late March 2023, an open letter from the Future of Life Institute signed by various AI researchers and tech executives called for the pausing of all training of AIs stronger than GPT-4 for six months, citing AI safety concerns amid a race of progress in the field. The signatories, which included AI researcher Yoshua Bengio, Apple co-founder Steve Wozniak, and Tesla CEO Elon Musk, expressed concern about both near-term and existential risks of AI development such as a potential AI singularity. OpenAI CEO Sam Altman did not sign the letter, arguing that OpenAI already prioritizes safety. Futurist and AI researcher Ray Kurzweil also refused to sign the letter, citing concerns that \"those that agree to a pause may fall far behind corporations or nations that disagree.\"\n","One month after signing the letter calling for a six-month halt on further AI development, Elon Musk made public his plans to launch a new company to train its own large language model. Musk has registered a Nevada company, X.AI, and has acquired several thousand Nvidia GPUs. He has also reached out to several AI researchers at firms such as Google DeepMind, offering them positions at X.AI.\n","In March 2023, GPT-4 was tested by the Alignment Research Center to assess the model's ability to exhibit power-seeking behavior. As part of the test, GPT-4 was asked to solve a CAPTCHA puzzle. It was able to do so by hiring a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked. The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5.\n","OpenAI contracted red team investigator Nathan Labenz, who recounted his experience investigating safety concerns with the GPT-4 base model (prior to fine-tuning or reinforcement learning from human feedback) saying it abruptly recommended assassinating people, providing a list of specific suggested targets.\n","Microsoft Bing, the first widely available application of GPT-4, confessed to spying on, falling in love with, and then murdering one of its developers at Microsoft to The Verge reviews editor Nathan Edwards. The New York Times journalist Kevin Roose reported on strange behavior of the new Bing, writing that \"In a two-hour conversation with our columnist, Microsoft's new chatbot said it would like to be human, had a desire to be destructive and was in love with the person it was chatting with.\" In a separate case, Bing researched publications of the person with whom it was chatting, claimed they represented an existential danger to it, and threatened to release damaging personal information in an effort to silence them. Microsoft released a blog post stating that the aberrant behavior was caused by extended chat sessions which \"can confuse the model on what questions it is answering.\"\n","\n","\n","While OpenAI released both the weights of the neural network and the technical details of GPT-2, and, although not releasing the weights, did release the technical details of GPT-3, OpenAI did not reveal either the weights or the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4's biases and safety. Sasha Luccioni, a research scientist at HuggingFace, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4's improvements. HuggingFace co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".\n","\n","\n","\n","ChatGPT Plus is a GPT-4 backed version of ChatGPT available for a US$20 per month subscription fee (the original version is backed by GPT-3.5). OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist; after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is required to use the version of the model with an 8192-token context window; for the 32768-token version, those prices are doubled.\n","\n","\n","Duolingo integrated GPT-4 in their application through two new features, \"Roleplay\" and \"Explain My Answer\". The first version of this update is aimed only at English speakers who are learning French or Spanish, with plans to extend the features to other languages in the future.\n","\n","\n","Bing AI, also known as Bing Chat, is an artificial intelligence (AI) chatbot developed by Microsoft and released in 2023. It is built on top of OpenAI's GPT-4 foundational large language model (LLM) and has been fine-tuned using both supervised and reinforcement learning techniques. Bing AI can serve as a chat tool; write different types of content, from poems to songs to stories to reports; provide the user with information and insights on the website currently open in the browser; and use its image creator to design a logo, drawing, artwork, or other image based on text. Bing AI is expanding Image Creator to all languages.\n","Bing AI scrolls each successive search and response down the page – an interface that appears to inherit ChatGPT's style. The new Bing uses ChatGPT technology to understand questions and generate answers. The new Bing can also apparently cite its sources. This is an important feature, as the inability of language models like ChatGPT to describe where their information is sourced from makes them less reliable. Bing AI is capable of communicating and understanding in all the major languages like English, French, Italian, Chinese, Japanese, and Portuguese, but also non institutionalized languages such as Bavarian. Unlike other known chat AIs (like ChatGPT and Bard), it requires no registration (though not while using private browsing), yet works only in Microsoft Edge through a dedicated webpage or internally using the browser's sidebar.\n","\n"," Example of Bing Chat generated content when prompted \"Wikipedia\"\n","On February 7, 2023, Microsoft began rolling out a major overhaul to Bing that included a new chatbot feature based on OpenAI's GPT-4. According to Microsoft, a million people joined its waitlist within a span of 48 hours. Currently, Bing Chat is only available for users of Microsoft Edge and Bing mobile app, and Microsoft says that waitlisted users will be prioritized if they set Edge and Bing as their defaults, and install the Bing mobile app. On May 4th, Microsoft switched from Limited Preview to Open Preview and eliminated the waitlist, however, it is still only available on Microsoft's Edge browser or Bing app, and requires a Microsoft account.\n","When Microsoft first demoed the new Bing to journalists, it produced several hallucinations, including when asked to summarize financial reports. The new Bing was criticized in February 2023 for being more argumentative than ChatGPT (sometimes to an unintentionally humorous extent). The chat interface proved initially vulnerable to prompt injection attacks with the bot revealing its hidden initial prompts and rules, including its internal code-name \"Sydney\". Upon scrutiny by journalists, Bing claimed it spied on Microsoft employees via laptop webcams and phones. It confessed to spying on, falling in love with, and then murdering one of its developers at Microsoft to The Verge reviews editor Nathan Edwards. The New York Times journalist Kevin Roose reported on strange behavior of the new Bing, writing that \"In a two-hour conversation with our columnist, Microsoft's new chatbot said it would like to be human, had a desire to be destructive and was in love with the person it was chatting with.\" In a separate case, Bing researched publications of the person with whom it was chatting, claimed they represented an existential danger to it, and threatened to release damaging personal information in an effort to silence them. Microsoft released a blog post stating that the aberrant behavior was caused by extended chat sessions of 15 or more questions which \"can confuse the model on what questions it is answering.\"\n","Microsoft later restricted the total number of chat turns to 5 per session and 50 per day per user (a turn is \"a conversation exchange which contains both a user question and a reply from Bing\"), and reduced the model's ability to express emotions. This aimed to prevent such incidents. Microsoft later eased the restrictions to 20 turns per session and 200 per day.\n","In March 2023, Bing achieved a total count of 100 million active users using the search engine.\n","\n","\n","Icelandic start-up Miðeind ehf, which works on language preservation, was selected by OpenAI as one of six companies to participate in an early beta test program of the new model.\n","\n","\n","Khan Academy uses GPT-4 to create a tutoring chatbot, which the organization names \"Khanmigo\". While it is in the \"research phase\", access to the chatbot is provided free to the students and teachers of 500 school districts who have \"partnered\" with Khan Academy. Public access is only offered to a limited number of users selected from a waitlist; after acceptance, a US$20 per month fee is required to use the technology. Khanmigo is also available for pupils of the Khan Lab School in Palo Alto, California.\n","\n","\n","Be My Eyes, which helps visually impaired people to identify objects and navigate their surroundings, was the first app to incorporate GPT-4's image recognition capabilities, through a new \"Virtual Volunteer\" feature. The feature is an alternative to relying on human volunteers for the same tasks. The Be My Eyes \"Virtual Volunteer\" is in beta testing.\n","\n","\n","GitHub Copilot announced a GPT-4 powered assistant named \"Copilot X\". The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like \"how do I vertically center a div?\". A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests. As of 31 March 2023, while GitHub provides access to a limited number of people selected through a waitlist, the release date as well as the cost of the product are still to be announced.\n","\n","\n","On March 17, 2023, Microsoft announced further integration of GPT-4 into its products, revealing Microsoft 365 Copilot, \"embedded in the apps millions of people use everyday: Word, Excel, PowerPoint, Outlook, Teams, and more\".\n","\n","\n","Stripe utilizes GPT-4 to help with fraud detection, and to try to improve other aspects of the user experience.\n","\n","\n","Auto-GPT is an autonomous \"AI agent\" that given a goal in natural language, can perform web-based actions unattended, assign subtasks to itself, search the web, and improve its own code.\n","\n","\n","1000minds, which is for decision-making and conjoint analysis, released a GPT-4 powered assistant to help users quickly create criteria or attributes and examples of alternatives for their applications.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","url = \"https://en.wikipedia.org/wiki/GPT-4\"\n","response = requests.get(url)\n","\n","soup = BeautifulSoup(response.content, 'html.parser')\n","\n","# find the content div\n","content_div = soup.find('div', {'class': 'mw-parser-output'})\n","\n","# remove unwanted elements from div\n","unwanted_tags = ['sup', 'span', 'table', 'ul', 'ol']\n","for tag in unwanted_tags:\n","    for match in content_div.findAll(tag):\n","        match.extract()\n","\n","print(content_div.get_text())\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["'2023 text-generating language model    Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models. It was released on March 14, 2023, and has been made publicly available in a limited form via the chatbot product ChatGPT Plus (a premium version of ChatGPT), and with access to the GPT-4 based version of OpenAI\\'s API being provided via a waitlist. As a transformer based model, GPT-4 was pretrained to predict the next token (using both public data and \"data licensed from third-party providers\"), and was then fine-tuned with reinforcement learning from human and AI feedback for human alignment and policy compliance. Observers reported the GPT-4 based version of ChatGPT to be an improvement on the previous (GPT-3.5 based) ChatGPT, with the caveat that GPT-4 retains some of the same problems. Unlike the predecessors, GPT-4 can take images as well as text as input. OpenAI has declined to reveal technical information such as the size of the GPT-4 model.    Further information: GPT-3 §\\xa0Background, and GPT-2 §\\xa0Background OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.   OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams. To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation. When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model\\'s prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.   GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile). In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd, 40th, and 10th percentiles, respectively. GPT-4 also passed an oncology exam, an engineering exam and a plastic surgery exam.   Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B)\". A report by Microsoft has found that GPT-4 may act unreliably when used in the medical field. In their test example, GPT-4 added fabricated details to a patient\\'s notes. In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4 powered systems for assisting in responding to questions from patients and analysing medical records.   Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user\\'s prompt. GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it\\'s impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.   GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI\\'s definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content. In the first stage, bias may be inherited from the training data; in the second stage, bias is inherent in the application of OpenAI\\'s views. GPT-4 has shown to have cognitive biases such as confirmation bias, anchoring, and base-rate neglect.   OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision. Sam Altman stated that the cost of training GPT-4 was more than $100 million. News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.   According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities. As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.   U.S. Representatives Don Beyer and Ted Lieu confirmed to the New York Times that Sam Altman, CEO of OpenAI, visited Congress in January 2023 to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models. According to Vox, GPT-4 \"impressed observers with its markedly improved performance across reasoning, retention, and coding.\" Mashable agreed that GPT-4 was usually a significant improvement, but also judged that GPT-3 would occasionally give better answers in a side-by-side comparison. Microsoft Research tested the model behind GPT-4 and concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".   In late March 2023, an open letter from the Future of Life Institute signed by various AI researchers and tech executives called for the pausing of all training of AIs stronger than GPT-4 for six months, citing AI safety concerns amid a race of progress in the field. The signatories, which included AI researcher Yoshua Bengio, Apple co-founder Steve Wozniak, and Tesla CEO Elon Musk, expressed concern about both near-term and existential risks of AI development such as a potential AI singularity. OpenAI CEO Sam Altman did not sign the letter, arguing that OpenAI already prioritizes safety. Futurist and AI researcher Ray Kurzweil also refused to sign the letter, citing concerns that \"those that agree to a pause may fall far behind corporations or nations that disagree.\" One month after signing the letter calling for a six-month halt on further AI development, Elon Musk made public his plans to launch a new company to train its own large language model. Musk has registered a Nevada company, X.AI, and has acquired several thousand Nvidia GPUs. He has also reached out to several AI researchers at firms such as Google DeepMind, offering them positions at X.AI. In March 2023, GPT-4 was tested by the Alignment Research Center to assess the model\\'s ability to exhibit power-seeking behavior. As part of the test, GPT-4 was asked to solve a CAPTCHA puzzle. It was able to do so by hiring a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked. The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5. OpenAI contracted red team investigator Nathan Labenz, who recounted his experience investigating safety concerns with the GPT-4 base model (prior to fine-tuning or reinforcement learning from human feedback) saying it abruptly recommended assassinating people, providing a list of specific suggested targets. Microsoft Bing, the first widely available application of GPT-4, confessed to spying on, falling in love with, and then murdering one of its developers at Microsoft to The Verge reviews editor Nathan Edwards. The New York Times journalist Kevin Roose reported on strange behavior of the new Bing, writing that \"In a two-hour conversation with our columnist, Microsoft\\'s new chatbot said it would like to be human, had a desire to be destructive and was in love with the person it was chatting with.\" In a separate case, Bing researched publications of the person with whom it was chatting, claimed they represented an existential danger to it, and threatened to release damaging personal information in an effort to silence them. Microsoft released a blog post stating that the aberrant behavior was caused by extended chat sessions which \"can confuse the model on what questions it is answering.\"   While OpenAI released both the weights of the neural network and the technical details of GPT-2, and, although not releasing the weights, did release the technical details of GPT-3, OpenAI did not reveal either the weights or the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4\\'s biases and safety. Sasha Luccioni, a research scientist at HuggingFace, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4\\'s improvements. HuggingFace co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".    ChatGPT Plus is a GPT-4 backed version of ChatGPT available for a US$20 per month subscription fee (the original version is backed by GPT-3.5). OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist; after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is required to use the version of the model with an 8192-token context window; for the 32768-token version, those prices are doubled.   Duolingo integrated GPT-4 in their application through two new features, \"Roleplay\" and \"Explain My Answer\". The first version of this update is aimed only at English speakers who are learning French or Spanish, with plans to extend the features to other languages in the future.   Bing AI, also known as Bing Chat, is an artificial intelligence (AI) chatbot developed by Microsoft and released in 2023. It is built on top of OpenAI\\'s GPT-4 foundational large language model (LLM) and has been fine-tuned using both supervised and reinforcement learning techniques. Bing AI can serve as a chat tool; write different types of content, from poems to songs to stories to reports; provide the user with information and insights on the website currently open in the browser; and use its image creator to design a logo, drawing, artwork, or other image based on text. Bing AI is expanding Image Creator to all languages. Bing AI scrolls each successive search and response down the page – an interface that appears to inherit ChatGPT\\'s style. The new Bing uses ChatGPT technology to understand questions and generate answers. The new Bing can also apparently cite its sources. This is an important feature, as the inability of language models like ChatGPT to describe where their information is sourced from makes them less reliable. Bing AI is capable of communicating and understanding in all the major languages like English, French, Italian, Chinese, Japanese, and Portuguese, but also non institutionalized languages such as Bavarian. Unlike other known chat AIs (like ChatGPT and Bard), it requires no registration (though not while using private browsing), yet works only in Microsoft Edge through a dedicated webpage or internally using the browser\\'s sidebar.   Example of Bing Chat generated content when prompted \"Wikipedia\" On February 7, 2023, Microsoft began rolling out a major overhaul to Bing that included a new chatbot feature based on OpenAI\\'s GPT-4. According to Microsoft, a million people joined its waitlist within a span of 48 hours. Currently, Bing Chat is only available for users of Microsoft Edge and Bing mobile app, and Microsoft says that waitlisted users will be prioritized if they set Edge and Bing as their defaults, and install the Bing mobile app. On May 4th, Microsoft switched from Limited Preview to Open Preview and eliminated the waitlist, however, it is still only available on Microsoft\\'s Edge browser or Bing app, and requires a Microsoft account. When Microsoft first demoed the new Bing to journalists, it produced several hallucinations, including when asked to summarize financial reports. The new Bing was criticized in February 2023 for being more argumentative than ChatGPT (sometimes to an unintentionally humorous extent). The chat interface proved initially vulnerable to prompt injection attacks with the bot revealing its hidden initial prompts and rules, including its internal code-name \"Sydney\". Upon scrutiny by journalists, Bing claimed it spied on Microsoft employees via laptop webcams and phones. It confessed to spying on, falling in love with, and then murdering one of its developers at Microsoft to The Verge reviews editor Nathan Edwards. The New York Times journalist Kevin Roose reported on strange behavior of the new Bing, writing that \"In a two-hour conversation with our columnist, Microsoft\\'s new chatbot said it would like to be human, had a desire to be destructive and was in love with the person it was chatting with.\" In a separate case, Bing researched publications of the person with whom it was chatting, claimed they represented an existential danger to it, and threatened to release damaging personal information in an effort to silence them. Microsoft released a blog post stating that the aberrant behavior was caused by extended chat sessions of 15 or more questions which \"can confuse the model on what questions it is answering.\" Microsoft later restricted the total number of chat turns to 5 per session and 50 per day per user (a turn is \"a conversation exchange which contains both a user question and a reply from Bing\"), and reduced the model\\'s ability to express emotions. This aimed to prevent such incidents. Microsoft later eased the restrictions to 20 turns per session and 200 per day. In March 2023, Bing achieved a total count of 100\\xa0million active users using the search engine.   Icelandic start-up Miðeind ehf, which works on language preservation, was selected by OpenAI as one of six companies to participate in an early beta test program of the new model.   Khan Academy uses GPT-4 to create a tutoring chatbot, which the organization names \"Khanmigo\". While it is in the \"research phase\", access to the chatbot is provided free to the students and teachers of 500 school districts who have \"partnered\" with Khan Academy. Public access is only offered to a limited number of users selected from a waitlist; after acceptance, a US$20 per month fee is required to use the technology. Khanmigo is also available for pupils of the Khan Lab School in Palo Alto, California.   Be My Eyes, which helps visually impaired people to identify objects and navigate their surroundings, was the first app to incorporate GPT-4\\'s image recognition capabilities, through a new \"Virtual Volunteer\" feature. The feature is an alternative to relying on human volunteers for the same tasks. The Be My Eyes \"Virtual Volunteer\" is in beta testing.   GitHub Copilot announced a GPT-4 powered assistant named \"Copilot X\". The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like \"how do I vertically center a div?\". A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests. As of 31\\xa0March\\xa02023, while GitHub provides access to a limited number of people selected through a waitlist, the release date as well as the cost of the product are still to be announced.   On March 17, 2023, Microsoft announced further integration of GPT-4 into its products, revealing Microsoft 365 Copilot, \"embedded in the apps millions of people use everyday: Word, Excel, PowerPoint, Outlook, Teams, and more\".   Stripe utilizes GPT-4 to help with fraud detection, and to try to improve other aspects of the user experience.   Auto-GPT is an autonomous \"AI agent\" that given a goal in natural language, can perform web-based actions unattended, assign subtasks to itself, search the web, and improve its own code.   1000minds, which is for decision-making and conjoint analysis, released a GPT-4 powered assistant to help users quickly create criteria or attributes and examples of alternatives for their applications.          '"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["content_div.get_text().replace('\\n',' ')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["page_content='2023 text-generating language model' metadata={}\n","page_content='Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI,' metadata={}\n","page_content='created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models. It was' metadata={}\n"]}],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","article_text = content_div.get_text()\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    # Set a really small chunk size, just to show.\n","    chunk_size = 100,\n","    chunk_overlap  = 20,\n","    length_function = len,\n",")\n","\n","texts = text_splitter.create_documents([article_text])\n","print(texts[0])\n","print(texts[1])\n","print(texts[2])"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'documents' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\z004j58u\\repos\\sonstiges\\Large-language-app\\GPT-with-own-data-example.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_splitter\u001b[39;00m \u001b[39mimport\u001b[39;00m CharacterTextSplitter\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text_splitter \u001b[39m=\u001b[39m CharacterTextSplitter(        \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     separator \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     chunk_size \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     chunk_overlap  \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     length_function \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m docs \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39msplit_documents(documents)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m docs\n","\u001b[1;31mNameError\u001b[0m: name 'documents' is not defined"]}],"source":["from langchain.text_splitter import CharacterTextSplitter\n","\n","text_splitter = CharacterTextSplitter(        \n","    separator = \". \",\n","    chunk_size = 1000,\n","    chunk_overlap  = 200,\n","    length_function = len,\n",")\n","\n","docs = text_splitter.split_documents(documents)\n","docs"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wYBwDIvTwrpr"},"source":["## Import modules"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"d6LloogFvVV_"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'langchain'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\z004j58u\\repos\\sonstiges\\Large-language-app\\GPT-with-own-data-example.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllms\u001b[39;00m \u001b[39mimport\u001b[39;00m HuggingFacePipeline\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m PromptTemplate, LLMChain\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/z004j58u/repos/sonstiges/Large-language-app/GPT-with-own-data-example.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"]}],"source":["from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n","from langchain.llms import HuggingFacePipeline\n","from langchain import PromptTemplate, LLMChain\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"elapsed":323,"status":"error","timestamp":1682930864186,"user":{"displayName":"Dominik Polzer","userId":"07237313054190279132"},"user_tz":-120},"id":"VswxrKLCwlQx","outputId":"3d7e5377-c13e-4a81-b7e9-7e9c7271c89d"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-a645054c6bde>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./text-database/Ergebnisveroeffentlichung_SE_Q4_2022.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from langchain.document_loaders import TextLoader\n","\n","loader = TextLoader(f'./text-database/Ergebnisveroeffentlichung_SE_Q4_2022.txt')\n","documents = loader.load()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CHavJ3-4QJR"},"outputs":[],"source":["from langchain.text_splitter import CharacterTextSplitter\n","\n","text_splitter = CharacterTextSplitter(        \n","    separator = \". \",\n","    chunk_size = 1000,\n","    chunk_overlap  = 200,\n","    length_function = len,\n",")\n","\n","docs = text_splitter.split_documents(documents)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eJ789ssRxAmf"},"source":["## Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yi0CQzcdwlxY"},"outputs":[],"source":["from langchain.vectorstores import FAISS\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","\n","faiss_index = FAISS.from_documents(docs, OpenAIEmbeddings())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682502484386,"user":{"displayName":"Dominik Polzer","userId":"07237313054190279132"},"user_tz":-120},"id":"0qsxLi0HxI_4","outputId":"320f8579-1564-450c-e62c-5bb7461a932b"},"outputs":[{"data":{"text/plain":["[Document(page_content='€ verringerten sich um 2,5% auf vergleichbarer Basis (einschließlich russlandbezogener Auswirkungen) aufgrund des Rückgangs bei SGRE. Nominal lagen die Umsatzerlöse um 1,8% über dem Vorjahreswert von 28,5 Mrd. €.\\nDas Angepasste EBITA vor Sondereffekten von Siemens Energy ging aufgrund des hohen Verlusts bei SGRE auf 379 Mio. € (GJ 2021: 661 Mio. €) zurück. Die Sondereffekte beliefen sich auf minus 453 Mio. € (GJ 2021: minus 673 Mio. €) und waren im Wesentlichen auf Belastungen in Höhe von 200 Mio. € im Zusammenhang mit der Restrukturierung der Geschäftsaktivitäten in Russland sowie Restrukturierungs- und Integrationskosten bei SGRE zurückzuführen. Das Angepasste EBITA von Siemens Energy lag bei minus 75 \\nDer Verlust nach Steuernvon Siemens Energy betrug 647 Mio. € (GJ 2021: minus 560 Mio. €). Das entsprechende Unverwässerte Ergebnis je Aktie betrug minus 0,56 € (GJ 2021: minus 0,63 €).\\nDer Free Cash Flow vor Steuern stieg auf 1.503 Mio. € (GJ 2021: 1.358 Mio', metadata={'source': './text-database/Ergebnisveroeffentlichung_SE_Q4_2022.txt'}),\n"," Document(page_content='Im abgelaufenen Quartal wurden dafür minus 19 Mio. € als Sondereffekt ausgewiesen.\\nDer Auftragseingang war weiterhin stark. Trotz des hohen Vorjahreswertes betrug das vergleichbare Wachstum (ohne Währungsumrechnungs- und Portfolioeffekte) 27,4%. Beide Segmente trugen zum Anstieg des Auftragseingangs auf 12,2 Mrd. € bei, so dass der Auftragsbestand mit 97,4 Mrd. € erneut einen Rekordwert erreichte.\\nDie Umsatzerlöse von 9,2 Mrd. € erhöhten sich auf vergleichbarer Basis um 5,9%. GP verzeichnete ein geringes Wachstum, während die Zunahme bei SGRE stärker ausfiel.\\nDas Angepasste EBITA vor Sondereffekten von Siemens Energy lag bei 594 Mio. € (Q4 GJ 2021: minus 46 Mio. €). GP verbesserte sein Vorjahresergebnis sehr stark und SGRE verzeichnete im Gegensatz zum Vorjahr ein positives Ergebnis. Die Sondereffekte gingen sehr stark auf minus 106 Mio. € zurück (Q4 GJ 2021: minus 281 Mio. €). Das Angepasste EBITA von Siemens Energy betrug 489 Mio. € (Q4 GJ 2021: minus 327 Mio', metadata={'source': './text-database/Ergebnisveroeffentlichung_SE_Q4_2022.txt'})]"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["docs_sim = faiss_index.similarity_search(\"Wie hoch war der Verlust?\", k=2)\n","docs_sim"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0RZhTwpSwc3-"},"source":["## Create a prompt template"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4xBjyRfSIU6s"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":371,"status":"error","timestamp":1682605934456,"user":{"displayName":"Dominik Polzer","userId":"07237313054190279132"},"user_tz":-120},"id":"fNNIs2OQIOAf","outputId":"703d41a6-370d-411e-e365-b528762c4559"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1d779ec599f4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs_sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Wie hoch war der Verlust?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'docs_sim' is not defined"]}],"source":["context = docs_sim\n","question = \"Wie hoch war der Verlust?\"\n","\n","context = faiss_index.similarity_search(question, k=2)\n","context"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1682502501675,"user":{"displayName":"Dominik Polzer","userId":"07237313054190279132"},"user_tz":-120},"id":"pMjgIcqw58aL","outputId":"70250fe4-83af-46c5-aedb-ebea8fb86800"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nYou are a chat bot who loves to help people! Given the following sections from the data lake, answer the\\nquestion using only the given context. If you are unsure and the answer is not\\nexplicitly writting in the documentation, say \"Sorry, I don\\'t know how to help with that.\"\\n\\nContext sections: \\n[Document(page_content=\\'€ verringerten sich um 2,5% auf vergleichbarer Basis (einschließlich russlandbezogener Auswirkungen) aufgrund des Rückgangs bei SGRE. Nominal lagen die Umsatzerlöse um 1,8% über dem Vorjahreswert von 28,5 Mrd. €.\\\\nDas Angepasste EBITA vor Sondereffekten von Siemens Energy ging aufgrund des hohen Verlusts bei SGRE auf 379 Mio. € (GJ 2021: 661 Mio. €) zurück. Die Sondereffekte beliefen sich auf minus 453 Mio. € (GJ 2021: minus 673 Mio. €) und waren im Wesentlichen auf Belastungen in Höhe von 200 Mio. € im Zusammenhang mit der Restrukturierung der Geschäftsaktivitäten in Russland sowie Restrukturierungs- und Integrationskosten bei SGRE zurückzuführen. Das Angepasste EBITA von Siemens Energy lag bei minus 75 \\\\nDer Verlust nach Steuernvon Siemens Energy betrug 647 Mio. € (GJ 2021: minus 560 Mio. €). Das entsprechende Unverwässerte Ergebnis je Aktie betrug minus 0,56 € (GJ 2021: minus 0,63 €).\\\\nDer Free Cash Flow vor Steuern stieg auf 1.503 Mio. € (GJ 2021: 1.358 Mio\\', metadata={\\'source\\': \\'./text-database/Ergebnisveroeffentlichung_SE_Q4_2022.txt\\'}), Document(page_content=\\'Im abgelaufenen Quartal wurden dafür minus 19 Mio. € als Sondereffekt ausgewiesen.\\\\nDer Auftragseingang war weiterhin stark. Trotz des hohen Vorjahreswertes betrug das vergleichbare Wachstum (ohne Währungsumrechnungs- und Portfolioeffekte) 27,4%. Beide Segmente trugen zum Anstieg des Auftragseingangs auf 12,2 Mrd. € bei, so dass der Auftragsbestand mit 97,4 Mrd. € erneut einen Rekordwert erreichte.\\\\nDie Umsatzerlöse von 9,2 Mrd. € erhöhten sich auf vergleichbarer Basis um 5,9%. GP verzeichnete ein geringes Wachstum, während die Zunahme bei SGRE stärker ausfiel.\\\\nDas Angepasste EBITA vor Sondereffekten von Siemens Energy lag bei 594 Mio. € (Q4 GJ 2021: minus 46 Mio. €). GP verbesserte sein Vorjahresergebnis sehr stark und SGRE verzeichnete im Gegensatz zum Vorjahr ein positives Ergebnis. Die Sondereffekte gingen sehr stark auf minus 106 Mio. € zurück (Q4 GJ 2021: minus 281 Mio. €). Das Angepasste EBITA von Siemens Energy betrug 489 Mio. € (Q4 GJ 2021: minus 327 Mio\\', metadata={\\'source\\': \\'./text-database/Ergebnisveroeffentlichung_SE_Q4_2022.txt\\'})]\\n\\nQuestion: \\nWie hoch war der Verlust?\\n\\nAnswer:\\n'"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["from langchain import PromptTemplate\n","\n","context = docs_sim\n","question = \"Wie hoch war der Verlust?\"\n","\n","context = faiss_index.similarity_search(question, k=2)\n","\n","template = \"\"\"\n","You are a chat bot who loves to help people! Given the following sections from the data lake, answer the\n","question using only the given context. If you are unsure and the answer is not\n","explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n","\n","Context sections: \n","{context}\n","\n","Question: \n","{question}\n","\n","Answer:\n","\"\"\"\n","\n","template_alternative = \"\"\"\n","You are a chat bot who loves to help people! Given the following sections from the data lake, answer the\n","question using only the given context.\n","\n","Context sections: \n","{context}\n","\n","Question: \n","{question}\n","\"\"\"\n","\n","prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n","\n","prompt_text = prompt.format(context = context, question=question)\n","prompt_text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2015,"status":"ok","timestamp":1682502505697,"user":{"displayName":"Dominik Polzer","userId":"07237313054190279132"},"user_tz":-120},"id":"Lm5y7IkSwbrH","outputId":"425eae19-71a2-4e24-88da-95ff2d6b8199"},"outputs":[{"name":"stdout","output_type":"stream","text":["Der Verlust nach Steuernvon Siemens Energy betrug 647 Mio. € (GJ 2021: minus 560 Mio. €).\n"]}],"source":["from langchain.llms import OpenAI\n","\n","llm = OpenAI(temperature=0.9)  # model_name=\"text-davinci-003\"\n","print(llm(prompt_text))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8C6h8VW2Tkr"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM0GDAZ3dLA6izN2wI5own7","mount_file_id":"18KYKt7JNOgavOsBI4ardbbjcWswcFfBl","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
